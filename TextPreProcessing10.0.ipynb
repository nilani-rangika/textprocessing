{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Jcharis/Natural-Language-Processing-Tutorials/blob/master/Training%20the%20Named%20Entity%20Recognizer%20in%20SpaCy.ipynb\n",
    "#https://spacy.io/usage/training#ner\n",
    "import plac\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 39\n"
     ]
    }
   ],
   "source": [
    "example = \"Heavy rain closes roads in Christchurch, causes flooding.\"\n",
    "for match in re.finditer('Christchurch', example):\n",
    "    print(match.start(), match.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = \"CAUSE\"\n",
    "\n",
    "TRAIN_DATA = [\n",
    "(\"Heavy rain closes roads in Christchurch, causes flooding\",{\"entities\":[(0, 10, LABEL), (11, 23,\"EVENT\"), (27, 39,\"GPE\"), (48, 56,LABEL)]}),\n",
    "(\"Deadly storm causes travel chaos amid evacuations and widespread flooding\",{\"entities\":[(65, 73,LABEL), (20, 32, \"EVENT\")]}),\n",
    "(\"Roads under water and fallen trees, as storm wreaks havoc on region\",{\"entities\":[(0, 17,\"EVENT\"), (22, 34,\"EVENT\"), (39, 44, LABEL)]}),\n",
    "(\"Tree fall in Rotorua kills woman in car\",{\"entities\":[(0, 9, LABEL), (13, 20,\"GPE\"), (21, 26,\"EVENT\")]}),\n",
    "(\"Thames Coast road severely damaged in wake of storm\",{\"entities\":[(0, 17,\"LOC\"), (18, 34,\"EVENT\"), (46, 51, LABEL)]}),\n",
    "(\"Flooding closes roads, inundates homes in Auckland\",{\"entities\":[(0, 8, LABEL), (9, 21,\"EVENT\"), (42, 50,\"GPE\")]}),\n",
    "(\"Wild weather batters the Bay of Plenty\",{\"entities\":[(0, 12, LABEL), (13, 20,\"EVENT\"), (25, 38,\"GPE\")]}),\n",
    "(\"Storm hit power supplies almost restored\",{\"entities\":[(0, 5, LABEL), (6, 24,\"EVENT\"), (32, 40,\"EVENT\")]}),\n",
    "(\"State of emergency declared in Nelson Tasman District\",{\"entities\":[(0, 27,\"EVENT\"), (31, 37,\"GPE\"), (38, 37,\"GPE\")]}),\n",
    "(\"Several Christchurch residents evacuate as Heathcote River threatens to overflow\",{\"entities\":[(8, 20,\"GPE\"), (31, 39,\"EVENT\"), (43, 58,\"LOC\"), (72, 80, LABEL)]}),\n",
    "(\"Cyclone Gita: Wild weather grounds flights, knocks down power pole in Wellington\",{\"entities\":[(0, 12, LABEL1), (27, 42,\"EVENT\"), (44, 66,\"EVENT\"), (70, 80,\"GPE\")]}),\n",
    "(\"Former cyclone Gita crosses New Zealand, leaving destruction in its wake\",{\"entities\":[(7, 19, LABEL1), (28, 39,\"EVENT\")]}),\n",
    "(\"Cyclone Gita aftermath: What you need to know\",{\"entities\":[(0, 12, LABEL1)]}),\n",
    "(\"Houses evacuated at Kāpiti Coast as high tide and heavy rain cause flooding\",{\"entities\":[(7, 16,\"EVENT\"), (20, 32,\"GPE\"), (36, 45,LABEL), (50, 60,LABEL), (67, 75,LABEL)]}),\n",
    "(\"Takaka Hill road partially reopens, to the relief of those trapped in Golden Bay after Gita\",{\"entities\":[(0, 16,\"LOC\"), (17, 34,\"EVENT\"), (70, 80,\"LOC\"), (87, 91,LABEL1)]}),\n",
    "(\"State Highway 1 through Kaikōura likely to remain closed until end of the week\",{\"entities\":[(0, 15,\"FAC\"),(24, 32,\"GPE\"),(43, 56,\"EVENT\"),(63, 78,\"DATE\")]}),\n",
    "(\"Takaka Hill road to fully re-open from next weekend\",{\"entities\":[(0, 16,\"LOC\"), (20, 33,\"EVENT\"), (39, 51,\"DATE\")]}),\n",
    "(\"Never seen it like this: Homes flooded, roads closed by storm\",{\"entities\":[(25, 38,\"EVENT\"), (40, 52,\"EVENT\"), (56, 61, LABEL)]}),\n",
    "(\"Flights disrupted and roads closed as high winds continue to batter Wellington\",{\"entities\":[(0, 17,\"EVENT\"), (22, 34,\"EVENT\"), (38, 48, LABEL), (68, 78,\"GPE\")]}),\n",
    "(\"Local state of emergency declared, homes evacuated as heavy rain, gales thrash West Coast\",{\"entities\":[(0, 33,\"EVENT\"), (41, 50,\"EVENT\"), (54, 64, LABEL),(79, 89,\"GPE\")]}),\n",
    "(\"As it happened: West Coast bridge washed away as rivers reach record levels\",{\"entities\":[(16, 33,\"FAC\"), (34, 45,\"EVENT\")]}),\n",
    "(\"Coasters on clean-up duty have till Sunday before the rain returns\",{\"entities\":[(36, 42,\"DATE\")]}),\n",
    "(\"Vital Waiho River bridge reopens, reconnecting a recovering West Coast\",{\"entities\":[(6, 24,\"FAC\"),(25, 32,\"EVENT\"),(60, 70,\"GPE\")]}),\n",
    "(\"Tornado clean-up begins as Key heads to destruction zone\",{\"entities\":[(8, 23,\"EVENT\"), (0, 7,LABEL)]}),\n",
    "(\"Rotorua tornado: Calves tossed into the air\",{\"entities\":[(0, 7,\"GPE\"), (8, 15, LABEL), (17, 43, \"EVENT\")]}),\n",
    "(\"Snow spotted in central Wellington\",{\"entities\":[(0, 12,\"EVENT\"), (24, 34,\"GPE\")]}),\n",
    "(\"Wellington's coldest day on record\",{\"entities\":[(0, 10,\"GPE\"), (13, 34,\"EVENT\")]}),\n",
    "(\"Region freezes with big chill\",{\"entities\":[(0, 14,\"EVENT\")]}),\n",
    "(\"Snow forces Wellington schools to close\",{\"entities\":[(12, 22,\"GPE\"), (23, 39,\"EVENT\")]}),\n",
    "(\"One person dead after crash involving car and cyclist on SH2 north of Wellington\",{\"entities\":[(0, 3,\"CARDINAL\"), (11, 15,\"EVENT\"), (22, 27,LABEL), (57, 66,\"FAC\"),(70, 80,\"GPE\")]}),\n",
    "(\"Strong 5.8 magnitude quake near Levin\",{\"entities\":[(7, 10,\"CARDINAL\"), (21, 26,\"EVENT\"), (32, 37,\"GPE\")]}),\n",
    "(\"Eight people hurt, one seriously, in Southland crash\",{\"entities\":[(0, 5,\"CARDINAL\"), (13, 17,\"EVENT\"), (19, 22,\"CARDINAL\"), (37, 46,\"GPE\")]}),\n",
    "(\"Vital Waiho River bridge reopens, reconnecting a recovering West Coast\",{\"entities\":[(6, 24,\"FAC\"), (25, 32,\"EVENT\"), (60, 70,\"GPE\")]}),\n",
    "(\"Warnings as polar blast hits country\",{\"entities\":[(12, 28,\"EVENT\")]}),\n",
    "(\"Five crashes on Auckland's Southwestern Motorway\",{\"entities\":[(5, 12,\"EVENT\"), (16, 24,\"GPE\"), (27, 48,\"FAC\")]}),\n",
    "(\"Auckland motorway closure: drivers asked to avoid area\",{\"entities\":[(0, 8,\"FAC\"), (18, 25,\"EVENT\"), (27, 54,\"EVENT\")]}),\n",
    "(\"Major weather disruption around NZ\",{\"entities\":[(32, 34,\"GPE\")]}),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (\"Big freeze: Worst over but disruption remains\",{\"entities\":[(0, 45,\"GPE\")]}),\n",
    "# (\"Icy blast moves up from south\",{\"entities\":[(0, 29,\"GPE\")]}),\n",
    "# (\"Wintry blast brings country to a standstill\",{\"entities\":[(0, 43,\"GPE\")]}),\n",
    "# (\"Christchurch's new white zone\",{\"entities\":[(0, 29,\"GPE\")]}),\n",
    "# (\"Worst over but snow could hit hills\",{\"entities\":[(0, 35,\"GPE\")]}),\n",
    "# (\"Wellington's 'once in a lifetime' polar blast\",{\"entities\":[(0, 45,\"GPE\")]}),\n",
    "# (\"Another three days of snow for Wellington\",{\"entities\":[(0, 41,\"GPE\")]}),\n",
    "# (\"Wellington snow most severe since 1976\",{\"entities\":[(0, 38,\"GPE\")]}),\n",
    "# (\"Black ice a risk as weather eases\",{\"entities\":[(0, 33,\"GPE\")]}),\n",
    "# (\"Snow closes Nelson roads\",{\"entities\":[(0, 24,\"GPE\")]}),\n",
    "# (\"Snow showers will ease tomorrow\",{\"entities\":[(0, 31,\"GPE\")]}),\n",
    "# (\"As it happened: West Coast bridge washed away as rivers reach record levels\",{\"entities\":[(0, 75,\"GPE\")]}),\n",
    "# (\"Live updates: West Coast flooding day 2\",{\"entities\":[(0, 39,\"GPE\")]}),\n",
    "# (\"Coasters on clean-up duty have till Sunday before the rain returns\",{\"entities\":[(0, 66,\"GPE\")]}),\n",
    "# (\"Live updates: Nelson fire\",{\"entities\":[(0, 25,\"GPE\")]}),\n",
    "# (\"Nelson fire: All you need to know\",{\"entities\":[(0, 33,\"GPE\")]}),\n",
    "# (\"Nelson fire: Fire contained, evacuated residents return home\",{\"entities\":[(0, 60,\"GPE\")]}),\n",
    "# (\"Giant hail stones hammer Timaru as storm moves up the country\",{\"entities\":[(0, 61,\"GPE\")]}),\n",
    "# (\"Wellington, Central North Island 5.8 magnitude earthquake had no known links to major fault lines\",{\"entities\":[(0, 97,\"GPE\")]}),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'en_core_web_sm'\n",
    "output_dir=Path(\"/home/rangika/PythonCode/TrainedModel2.0\")\n",
    "n_iter=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'en_core_web_sm'\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "if model is not None:\n",
    "    nlp = spacy.load(model)  # load existing spaCy model\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner.add_label(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 61.66876282527873}\n",
      "Losses {'ner': 57.317302166021676}\n",
      "Losses {'ner': 47.51047554269553}\n",
      "Losses {'ner': 49.49937161026551}\n",
      "Losses {'ner': 47.20177820772264}\n",
      "Losses {'ner': 53.16326780825594}\n",
      "Losses {'ner': 46.26461603723419}\n",
      "Losses {'ner': 40.15023700479276}\n",
      "Losses {'ner': 48.4969237564662}\n",
      "Losses {'ner': 45.00271484762213}\n",
      "Losses {'ner': 45.38826974946349}\n",
      "Losses {'ner': 41.99459004196251}\n",
      "Losses {'ner': 44.965490107017104}\n",
      "Losses {'ner': 36.78450473284465}\n",
      "Losses {'ner': 45.986399406530836}\n",
      "Losses {'ner': 47.78294669950452}\n",
      "Losses {'ner': 43.830482330173254}\n",
      "Losses {'ner': 40.69150386082765}\n",
      "Losses {'ner': 42.307795716183875}\n",
      "Losses {'ner': 40.49295756596812}\n"
     ]
    }
   ],
   "source": [
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    move_names = list(ner.move_names)\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    # only train NER\n",
    "    with nlp.disable_pipes(*other_pipes) and warnings.catch_warnings():\n",
    "        # show warnings for misaligned entity spans once\n",
    "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            batches = minibatch(TRAIN_DATA, size=sizes)\n",
    "            losses = {}\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Thames Coast road', 'LOC'), ('severely damaged', 'EVENT')]\n",
      "Entities [('Heavy rain', 'CAUSE'), ('closes roads', 'EVENT'), ('Christchurch', 'GPE')]\n",
      "Entities [('Roads under water', 'EVENT'), ('fallen trees', 'EVENT')]\n",
      "Entities [('travel chaos', 'EVENT')]\n",
      "Entities [('closes roads', 'EVENT'), ('Auckland', 'GPE')]\n",
      "Entities [('Tree fall', 'CAUSE'), ('Rotorua', 'GPE'), ('kills', 'EVENT')]\n"
     ]
    }
   ],
   "source": [
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    #print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to /home/rangika/PythonCode/TrainedModel2.0\n"
     ]
    }
   ],
   "source": [
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /home/rangika/PythonCode/TrainedModel2.0\n",
      "Wellington 34 44 GPE\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "# Check the classes have loaded back consistently\n",
    "\n",
    "test_text = 'Police rescue elderly person from Wellington Urban Motorway'\n",
    "\n",
    "doc2 = nlp2(test_text)\n",
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 50.021389760077}\n",
      "Losses {'ner': 61.220083832740784}\n",
      "Losses {'ner': 50.672827993286774}\n",
      "Losses {'ner': 55.53044503927231}\n",
      "Losses {'ner': 49.35659373732051}\n",
      "Losses {'ner': 49.353583195068495}\n",
      "Losses {'ner': 50.50948077440262}\n",
      "Losses {'ner': 57.487945690751076}\n",
      "Losses {'ner': 43.21051198942587}\n",
      "Losses {'ner': 59.233455926470924}\n",
      "Losses {'ner': 57.011119186878204}\n",
      "Losses {'ner': 57.974149748682976}\n",
      "Losses {'ner': 55.35906386375427}\n",
      "Losses {'ner': 47.17279011383653}\n",
      "Losses {'ner': 49.17373274639249}\n",
      "Losses {'ner': 53.8401700258255}\n",
      "Losses {'ner': 50.92825764417648}\n",
      "Losses {'ner': 52.06319758296013}\n",
      "Losses {'ner': 44.03205634839833}\n",
      "Losses {'ner': 56.8142254948616}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    # only train NER\n",
    "with nlp.disable_pipes(*other_pipes) and warnings.catch_warnings():\n",
    "        # show warnings for misaligned entity spans once\n",
    "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "\n",
    "        # reset and initialize the weights randomly – but only if we're\n",
    "        # training a new model\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text, _ in TRAIN_DATA:\n",
    "#     doc = nlp(text)\n",
    "#     print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "#     print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ef06345bad06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /home/rangika/PythonCode/TrainedModel1.0\n",
      "Southern Motorway 28 45 LOC\n",
      "The Transport Agency 67 87 ORG\n",
      "Southeastern Highway 136 156 LOC\n",
      "SH1 2:45PM 209 219 LOC\n",
      "South Eastern Hwy 254 271 LOC\n",
      "Akld Nthlnd 350 361 LOC\n",
      "November 14, 2019 362 379 DATE\n",
      "five 594 598 CARDINAL\n",
      "Megan Harvey 636 648 PERSON\n",
      "south motorway 658 672 LOC\n",
      "slam 689 693 FAC\n",
      "five 796 800 CARDINAL\n",
      "two 883 886 CARDINAL\n",
      "Harvey 898 904 ORG\n",
      "Ferrari Southern Motorway 945 970 LOC\n",
      "1pm 971 974 QUANTITY\n",
      "The Transport Agency 976 996 ORG\n",
      "two 1021 1024 CARDINAL\n",
      "Wellington Symonds 1069 1087 LOC\n",
      "three four 1117 1127 CARDINAL\n",
      "Symonds off-ramp 1137 1153 LOC\n",
      "Ferrari traffic 1196 1211 LOC\n"
     ]
    }
   ],
   "source": [
    "output_dir=Path(\"/home/rangika/PythonCode/TrainedModel1.0\")\n",
    "\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "\n",
    "# for text, _ in TRAIN_DATA:\n",
    "#     doc = nlp2(text)\n",
    "#     print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "#     print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "test_text = 'Motorists heading home work Southern Motorway expect delays crash. The Transport Agency said crash blocking right southbound lane prior Southeastern Highway off-ramp. Pass scene care expect delays directions. SH1 2:45PM crash right southbound lane prior South Eastern Hwy off-ramp. Pass scene care expect delays directions. pic.twitter.comfEXiaHdLaa Akld Nthlnd November 14, 2019 statement police said attended multi-car nose tail crash, reported one seriously hurt. Advertisement couple people reported minor injuries, serious injuries involved, police spokesperson said. witness said counted five cars involved crash. Herald reporter Megan Harvey, driving south motorway crash happened, slam brakes avoid pile-up. went pretty much 100kmh stopped She said stopping safely, passed crash site saw five cars affected knock-on effect. The guy front stopped pretty fast, almost hit him, two missed it, Harvey said. The crash follows breakdown black Ferrari Southern Motorway 1pm. The Transport Agency said breakdown resulted two lanes blocked. People advised expect delays Wellington Symonds due breakdown, blocking lane three four adjacent Symonds off-ramp. Advertisement Tow services since removed Ferrari traffic still slow people advised consider using alternate routes delay journeys.'\n",
    "\n",
    "doc = nlp2(test_text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Motorists heading home work \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Southern Motorway\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " expect delays crash. \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Transport Agency\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said crash blocking right southbound lane prior \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Southeastern Highway\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " off-ramp. Pass scene care expect delays directions. \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SH1 2:45PM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " crash right southbound lane prior \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    South Eastern Hwy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " off-ramp. Pass scene care expect delays directions. pic.twitter.comfEXiaHdLaa \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Akld Nthlnd\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    November 14, 2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " statement police said attended multi-car nose tail crash, reported one seriously hurt. Advertisement couple people reported minor injuries, serious injuries involved, police spokesperson said. witness said counted \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    five\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cars involved crash. Herald reporter \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Megan Harvey\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", driving \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    south motorway\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " crash happened, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    slam\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       " brakes avoid pile-up. went pretty much 100kmh stopped She said stopping safely, passed crash site saw \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    five\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cars affected knock-on effect. The guy front stopped pretty fast, almost hit him, \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " missed it, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harvey\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said. The crash follows breakdown black \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ferrari Southern Motorway\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1pm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Transport Agency\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " said breakdown resulted \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " lanes blocked. People advised expect delays \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wellington Symonds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " due breakdown, blocking lane \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three four\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " adjacent \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Symonds off-ramp\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Advertisement Tow services since removed \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ferrari traffic\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " still slow people advised consider using alternate routes delay journeys.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 31\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "example = 'Tree fall in Spaghetti Junction woman in car.'\n",
    "for match in re.finditer('Spaghetti Junction', example):\n",
    "    print(match.start(), match.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seven 0 5 CARDINAL\n",
      "mid-Canterbury 94 108 DATE\n",
      "Rakaia 117 123 GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "  \n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "  \n",
    "sentence = 'Seven people, including teenagers, have been taken to hospital after their car crashed in the mid-Canterbury town of Rakaia.\"'\n",
    "doc = nlp(sentence) \n",
    "  \n",
    "for ent in doc.ents: \n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seven NUM\n",
      "people NOUN\n",
      ", PUNCT\n",
      "including VERB\n",
      "teenagers NOUN\n",
      ", PUNCT\n",
      "have AUX\n",
      "been AUX\n",
      "taken VERB\n",
      "to ADP\n",
      "hospital NOUN\n",
      "after ADP\n",
      "their DET\n",
      "car NOUN\n",
      "crashed VERB\n",
      "in ADP\n",
      "the DET\n",
      "mid ADJ\n",
      "- ADJ\n",
      "Canterbury ADJ\n",
      "town NOUN\n",
      "of ADP\n",
      "Rakaia PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Seven people, including teenagers, have been taken to hospital after their car crashed in the mid-Canterbury town of Rakaia.\")\n",
    "for token in doc:\n",
    "    print(token,token.pos_)\n",
    "    \n",
    "# pos_tags = [(i, i.pos_) for i in doc]\n",
    "# pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs: ['backed', 'happened', 'westbound', 'asked', 'consider', 'using', 'following', 'remains', 'Consider', 'delaying', 'said', 'reopened', 'remained', 'link', 'Consider', 'delaying']\n"
     ]
    }
   ],
   "source": [
    "print(\"Verbs:\", [token.text for token in doc if token.pos_ == \"VERB\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Traffic, backed),\n",
       " (backed, happened),\n",
       " (km, happened),\n",
       " (incident, happened),\n",
       " (incident, happened),\n",
       " (happened, westbound),\n",
       " (pm, westbound),\n",
       " (link, westbound),\n",
       " (westbound, asked),\n",
       " (Drivers, asked),\n",
       " (asked, consider),\n",
       " (avoid, consider),\n",
       " (area, consider),\n",
       " (consider, using),\n",
       " (using, following),\n",
       " (route, following),\n",
       " (link, following),\n",
       " (westbound, following),\n",
       " (following, remains),\n",
       " (incident, remains),\n",
       " (Traffic, remains),\n",
       " (remains, Consider),\n",
       " (northbound, Consider),\n",
       " (westbound, Consider),\n",
       " (Consider, delaying),\n",
       " (delaying, said),\n",
       " (delays, said),\n",
       " (said, reopened),\n",
       " (road, reopened),\n",
       " (reopened, remained),\n",
       " (traffic, remained),\n",
       " (remained, link),\n",
       " (link, Consider),\n",
       " (journey, Consider),\n",
       " (km, Consider),\n",
       " (Advertisement, Consider),\n",
       " (Consider, delaying)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_adj_pairs = []\n",
    "for i,token in enumerate(doc):\n",
    "    if token.pos_ not in ('NOUN','VERB'):\n",
    "        continue\n",
    "    for j in range(i+1,len(doc)):\n",
    "        if doc[j].pos_ == 'VERB':\n",
    "            noun_adj_pairs.append((token,doc[j]))\n",
    "            break\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Traffic, 9),\n",
       " (incident, 12),\n",
       " (,, .),\n",
       " (Drivers, avoid),\n",
       " (area, using),\n",
       " (consider, alternative),\n",
       " (westbound, earlier),\n",
       " (Traffic, heavy),\n",
       " (., delaying),\n",
       " (Consider, journey),\n",
       " (Agency, 1.25pm),\n",
       " (road, traffic),\n",
       " (traffic, heavy),\n",
       " (Highway, journey),\n",
       " (Advertisement, delaying),\n",
       " (Consider, journey)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owners_possessions = [] \n",
    "for i in pos_tags:\n",
    "    if i[1] == \"VERB\":\n",
    "        owner = i[0].nbor(-1)\n",
    "        possession = i[0].nbor(1)\n",
    "        owners_possessions.append((owner, possession))\n",
    "owners_possessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seven people</td>\n",
       "      <td>people</td>\n",
       "      <td>nsubjpass</td>\n",
       "      <td>taken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teenagers</td>\n",
       "      <td>teenagers</td>\n",
       "      <td>pobj</td>\n",
       "      <td>including</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hospital</td>\n",
       "      <td>hospital</td>\n",
       "      <td>pobj</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>their car</td>\n",
       "      <td>car</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>crashed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mid-Canterbury town</td>\n",
       "      <td>town</td>\n",
       "      <td>pobj</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rakaia</td>\n",
       "      <td>Rakaia</td>\n",
       "      <td>pobj</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         a          b          c          d\n",
       "0             Seven people     people  nsubjpass      taken\n",
       "1                teenagers  teenagers       pobj  including\n",
       "2                 hospital   hospital       pobj         to\n",
       "3                their car        car      nsubj    crashed\n",
       "4  the mid-Canterbury town       town       pobj         in\n",
       "5                   Rakaia     Rakaia       pobj         of"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dependancy Parcing\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Seven people, including teenagers, have been taken to hospital after their car crashed in the mid-Canterbury town of Rakaia.\")\n",
    "a = []\n",
    "b = []\n",
    "c = []\n",
    "d = []\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    a.append(chunk.text)\n",
    "    b.append(chunk.root.text)\n",
    "    c.append(chunk.root.dep_)\n",
    "    d.append(chunk.root.head.text)\n",
    "    \n",
    "df = pd.DataFrame({'a': a, 'b': b, 'c': c, 'd':d})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seven nummod people NOUN []\n",
      "people nsubjpass taken VERB [Seven, ,, including, ,]\n",
      ", punct people NOUN []\n",
      "including prep people NOUN [teenagers]\n",
      "teenagers pobj including VERB []\n",
      ", punct people NOUN []\n",
      "have aux taken VERB []\n",
      "been auxpass taken VERB []\n",
      "taken ROOT taken VERB [people, have, been, to, crashed, .]\n",
      "to prep taken VERB [hospital]\n",
      "hospital pobj to ADP []\n",
      "after mark crashed VERB []\n",
      "their poss car NOUN []\n",
      "car nsubj crashed VERB [their]\n",
      "crashed advcl taken VERB [after, car, in]\n",
      "in prep crashed VERB [town]\n",
      "the det town NOUN []\n",
      "mid dep - ADJ []\n",
      "- dep Canterbury ADJ [mid]\n",
      "Canterbury amod town NOUN [-]\n",
      "town pobj in ADP [the, Canterbury, of]\n",
      "of prep town NOUN [Rakaia]\n",
      "Rakaia pobj of ADP []\n",
      ". punct taken VERB []\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Seven people, including teenagers, have been taken to hospital after their car crashed in the mid-Canterbury town of Rakaia.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{crashed}\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import nsubj, VERB\n",
    "\n",
    "verbs = set()\n",
    "for possible_subject in doc:\n",
    "    if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
    "        verbs.add(possible_subject.head)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
